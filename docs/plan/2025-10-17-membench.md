# membench Implementation Plan

> **For Claude:** Use `${SUPERPOWERS_SKILLS_ROOT}/skills/collaboration/executing-plans/SKILL.md` to implement this plan task-by-task.

**Goal:** Build a privacy-preserving memcache traffic capture and replay tool for benchmarking, capturing request/response distributions and replaying realistic traffic patterns without exposing sensitive keys/values.

**Architecture:** Two-phase tool: Record mode captures memcache traffic via libpcap, anonymizes keys (storing only hash+size), and serializes to a compact binary profile. Replay mode reads the profile, analyzes distributions, and generates semi-deterministic traffic matching command/key/value distributions from the capture.

**Tech Stack:** Rust, libpcap bindings (`pcap` crate), binary serialization (`bincode`), async I/O for replay

---

## Project Setup

### Task 1: Initialize Project Structure ✅ DONE

**Files:**
- Create: `Cargo.toml` (new project)
- Create: `src/main.rs`
- Create: `src/lib.rs`
- Create: `src/record/mod.rs`
- Create: `src/replay/mod.rs`
- Create: `src/profile/mod.rs`
- Create: `tests/integration_tests.rs`

**Step 1: Create new Rust binary project**

```bash
cargo new membench
cd membench
```

**Step 2: Update Cargo.toml with dependencies**

```toml
[package]
name = "membench"
version = "0.1.0"
edition = "2021"

[dependencies]
pcap = "1.1"
bincode = "1.3"
serde = { version = "1.0", features = ["derive"] }
tokio = { version = "1.35", features = ["full"] }
clap = { version = "4.4", features = ["derive"] }
anyhow = "1.0"
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
rand = "0.8"
siphasher = "0.3"

[dev-dependencies]
tempfile = "3.8"
```

**Step 3: Set up module structure**

Create `src/lib.rs`:
```rust
pub mod profile;
pub mod record;
pub mod replay;

pub use profile::{Event, ProfileMetadata, Response, CommandType, Flags};
```

Create `src/record/mod.rs`:
```rust
//! Capture and anonymization logic
```

Create `src/replay/mod.rs`:
```rust
//! Replay and traffic generation logic
```

Create `src/profile/mod.rs`:
```rust
//! Profile schema and serialization
```

**Step 4: Create main.rs with CLI skeleton**

```rust
use clap::{Parser, Subcommand};

#[derive(Parser)]
#[command(name = "membench")]
#[command(about = "Privacy-preserving memcache traffic capture and replay")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Capture memcache traffic from network interface
    Record {
        #[arg(short, long)]
        interface: String,
        #[arg(short, long, default_value = "11211")]
        port: u16,
        #[arg(short, long)]
        output: String,
        #[arg(short, long)]
        salt: Option<u64>,
    },
    /// Replay traffic from profile against target server
    Replay {
        #[arg(short, long)]
        input: String,
        #[arg(short, long, default_value = "localhost:11211")]
        target: String,
        #[arg(short, long, default_value = "4")]
        concurrency: usize,
    },
}

fn main() {
    tracing_subscriber::fmt::init();
    let cli = Cli::parse();
    match cli.command {
        Commands::Record { .. } => {
            println!("Record mode not yet implemented");
        }
        Commands::Replay { .. } => {
            println!("Replay mode not yet implemented");
        }
    }
}
```

**Step 5: Run and verify compilation**

```bash
cargo build
```

Expected: Compiles successfully, `membench --help` shows two subcommands.

**Step 6: Commit**

```bash
git add Cargo.toml src/ && git commit -m "feat: initialize membench project structure"
```

---

## Profile Schema Implementation

### Task 2: Define Event and Response Types ✅ DONE

**Files:**
- Modify: `src/profile/mod.rs`
- Create: `tests/profile_serde_tests.rs`

**Step 1: Write test for Event serialization**

Create `tests/profile_serde_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::profile::{Event, Response, CommandType, Flags};
    use std::collections::BTreeMap;

    #[test]
    fn test_event_serialization() {
        let event = Event {
            timestamp: 1000000,
            conn_id: 1,
            cmd_type: CommandType::Get,
            key_hash: 0x123456789abcdef0,
            key_size: 10,
            value_size: None,
            flags: Flags::empty(),
            response: Response::Found(100),
        };

        let encoded = bincode::serialize(&event).expect("encode");
        let decoded: Event = bincode::deserialize(&encoded).expect("decode");

        assert_eq!(decoded.timestamp, event.timestamp);
        assert_eq!(decoded.key_hash, event.key_hash);
    }

    #[test]
    fn test_response_variants() {
        let r1 = Response::Found(500);
        let r2 = Response::NotFound;
        let r3 = Response::Error;

        let encoded1 = bincode::serialize(&r1).unwrap();
        let encoded2 = bincode::serialize(&r2).unwrap();
        let encoded3 = bincode::serialize(&r3).unwrap();

        assert_eq!(bincode::deserialize::<Response>(&encoded1).unwrap(), r1);
        assert_eq!(bincode::deserialize::<Response>(&encoded2).unwrap(), r2);
        assert_eq!(bincode::deserialize::<Response>(&encoded3).unwrap(), r3);
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test profile_serde_tests
```

Expected: FAIL - types not defined.

**Step 3: Implement types in src/profile/mod.rs**

```rust
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Hash)]
pub enum CommandType {
    Get,
    Set,
    Delete,
    Noop,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
pub struct Flags {
    bits: u32,
}

impl Flags {
    pub fn empty() -> Self {
        Flags { bits: 0 }
    }

    pub fn with_quiet(mut self) -> Self {
        self.bits |= 1 << 0;
        self
    }

    pub fn has_quiet(&self) -> bool {
        (self.bits & (1 << 0)) != 0
    }

    pub fn with_value(mut self) -> Self {
        self.bits |= 1 << 1;
        self
    }

    pub fn has_value(&self) -> bool {
        (self.bits & (1 << 1)) != 0
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum Response {
    Found(u32),  // response_size
    NotFound,
    Error,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Event {
    pub timestamp: u64,
    pub conn_id: u32,
    pub cmd_type: CommandType,
    pub key_hash: u64,
    pub key_size: u32,
    pub value_size: Option<u32>,
    pub flags: Flags,
    pub response: Response,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ProfileMetadata {
    pub magic: u32,
    pub version: u8,
    pub total_events: u64,
    pub time_range: (u64, u64),
    pub unique_connections: u32,
    pub command_distribution: HashMap<CommandType, u64>,
}

impl ProfileMetadata {
    pub fn new() -> Self {
        ProfileMetadata {
            magic: 0xDEADBEEF,
            version: 1,
            total_events: 0,
            time_range: (0, 0),
            unique_connections: 0,
            command_distribution: HashMap::new(),
        }
    }
}
```

**Step 4: Run test to verify it passes**

```bash
cargo test --test profile_serde_tests
```

Expected: PASS.

**Step 5: Commit**

```bash
git add src/profile/mod.rs tests/profile_serde_tests.rs && git commit -m "feat: implement Event and Response types with serde"
```

---

## Record Phase: Packet Capture

### Task 3: Create Packet Capture Interface ✅ DONE

**Files:**
- Create: `src/record/capture.rs`
- Modify: `src/record/mod.rs`
- Create: `tests/record_capture_tests.rs`

**Step 1: Write test for capture interface**

Create `tests/record_capture_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::record::PacketCapture;

    #[test]
    fn test_capture_interface_creation() {
        // We can't fully test libpcap without real network setup,
        // but we can test the interface exists and responds to basic calls
        let devices = PacketCapture::list_devices();
        // Just verify we can list devices without panic
        assert!(devices.is_ok());
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test record_capture_tests
```

Expected: FAIL - `PacketCapture` not defined.

**Step 3: Implement packet capture wrapper in src/record/capture.rs**

```rust
use anyhow::{Context, Result};
use pcap::Capture;

pub struct PacketCapture {
    handle: Capture<pcap::Active>,
    port: u16,
}

impl PacketCapture {
    pub fn new(interface: &str, port: u16) -> Result<Self> {
        let mut cap = Capture::from_device(interface)
            .context("failed to open device")?
            .promisc(true)
            .snaplen(65535)
            .open()
            .context("failed to open capture")?;

        let filter = format!("tcp port {}", port);
        cap.filter(&filter, true)
            .context("failed to set filter")?;

        Ok(PacketCapture { handle: cap, port })
    }

    pub fn list_devices() -> Result<Vec<String>> {
        let devices = pcap::Device::list()
            .context("failed to list devices")?;
        Ok(devices.into_iter().map(|d| d.name).collect())
    }

    pub fn next_packet(&mut self) -> Result<&[u8]> {
        let packet = self.handle
            .next_packet()
            .context("failed to read packet")?;
        Ok(packet.data)
    }
}
```

**Step 4: Update src/record/mod.rs to export capture**

```rust
pub mod capture;
pub use capture::PacketCapture;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test record_capture_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/record/capture.rs src/record/mod.rs tests/record_capture_tests.rs && git commit -m "feat: add PacketCapture wrapper around libpcap"
```

---

### Task 4: Implement TCP Stream Reassembly ✅ DONE

**Files:**
- Create: `src/record/stream_reassembler.rs`
- Modify: `src/record/mod.rs`
- Create: `tests/stream_reassembler_tests.rs`

**Step 1: Write test for stream reassembly**

Create `tests/stream_reassembler_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::record::StreamReassembler;

    #[test]
    fn test_stream_reassembler_basic() {
        let mut reassembler = StreamReassembler::new();

        // Simulate TCP packets for a single connection
        let conn_id = (("127.0.0.1", 12345), ("127.0.0.1", 11211));

        // Add packet with data "hello"
        reassembler.add_packet(conn_id, 1000, b"hello");

        // Verify we can retrieve the stream data
        let data = reassembler.get_stream(conn_id);
        assert_eq!(data, b"hello");
    }

    #[test]
    fn test_stream_reassembler_out_of_order() {
        let mut reassembler = StreamReassembler::new();
        let conn_id = (("127.0.0.1", 12345), ("127.0.0.1", 11211));

        // Add packets out of order
        reassembler.add_packet(conn_id, 2000, b"world");
        reassembler.add_packet(conn_id, 1000, b"hello");

        // Should reassemble correctly
        let data = reassembler.get_stream(conn_id);
        assert_eq!(data, b"helloworld");
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test stream_reassembler_tests
```

Expected: FAIL - `StreamReassembler` not defined.

**Step 3: Implement stream reassembler in src/record/stream_reassembler.rs**

```rust
use std::collections::HashMap;

type ConnKey = ((&'static str, u16), (&'static str, u16));

pub struct StreamReassembler {
    streams: HashMap<ConnKey, StreamBuffer>,
}

struct StreamBuffer {
    segments: Vec<(u32, Vec<u8>)>,
}

impl StreamReassembler {
    pub fn new() -> Self {
        StreamReassembler {
            streams: HashMap::new(),
        }
    }

    pub fn add_packet(&mut self, conn_id: ConnKey, seq: u32, data: &[u8]) {
        let buffer = self.streams.entry(conn_id).or_insert_with(|| StreamBuffer {
            segments: Vec::new(),
        });

        buffer.segments.push((seq, data.to_vec()));
        buffer.segments.sort_by_key(|(seq, _)| *seq);
    }

    pub fn get_stream(&self, conn_id: ConnKey) -> Vec<u8> {
        if let Some(buffer) = self.streams.get(&conn_id) {
            buffer.segments.iter().flat_map(|(_, data)| data.iter().cloned()).collect()
        } else {
            Vec::new()
        }
    }
}
```

**Step 4: Run test to verify it passes**

```bash
cargo test --test stream_reassembler_tests
```

Expected: PASS.

**Step 5: Commit**

```bash
git add src/record/stream_reassembler.rs src/record/mod.rs tests/stream_reassembler_tests.rs && git commit -m "feat: implement TCP stream reassembly"
```

---

## Record Phase: Protocol Parsing

### Task 5: Implement Memcache Protocol Parser ✅ DONE

**Files:**
- Create: `src/record/parser.rs`
- Modify: `src/record/mod.rs`
- Create: `tests/memcache_parser_tests.rs`

**Step 1: Write tests for memcache protocol parsing**

Create `tests/memcache_parser_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::record::MemcacheParser;
    use membench::profile::{CommandType, Response};

    #[test]
    fn test_parse_get_request() {
        let input = b"mg testkey v\r\n";
        let parser = MemcacheParser::new();

        let (cmd, rest) = parser.parse_command(input).unwrap();
        assert_eq!(cmd.cmd_type, CommandType::Get);
        assert_eq!(cmd.key_range, 3..11); // "testkey"
    }

    #[test]
    fn test_parse_set_request() {
        let input = b"ms mykey 5\r\nhello\r\n";
        let parser = MemcacheParser::new();

        let (cmd, rest) = parser.parse_command(input).unwrap();
        assert_eq!(cmd.cmd_type, CommandType::Set);
        assert_eq!(cmd.value_size, Some(5));
    }

    #[test]
    fn test_parse_response_found() {
        let input = b"VA 5\r\nhello\r\n";
        let parser = MemcacheParser::new();

        let response = parser.parse_response(input).unwrap();
        match response.resp {
            Response::Found(size) => assert_eq!(size, 5),
            _ => panic!("expected Found"),
        }
    }

    #[test]
    fn test_parse_response_not_found() {
        let input = b"EN\r\n";
        let parser = MemcacheParser::new();

        let response = parser.parse_response(input).unwrap();
        assert_eq!(response.resp, Response::NotFound);
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test memcache_parser_tests
```

Expected: FAIL - `MemcacheParser` not defined.

**Step 3: Implement parser in src/record/parser.rs**

```rust
use anyhow::{anyhow, Result};
use membench::profile::{CommandType, Response, Flags};

pub struct ParsedCommand {
    pub cmd_type: CommandType,
    pub key_range: std::ops::Range<usize>,
    pub value_size: Option<u32>,
    pub flags: Flags,
}

pub struct ParsedResponse {
    pub resp: Response,
    pub consumed: usize,
}

pub struct MemcacheParser;

impl MemcacheParser {
    pub fn new() -> Self {
        MemcacheParser
    }

    pub fn parse_command(&self, input: &[u8]) -> Result<(ParsedCommand, &[u8])> {
        let line_end = input.iter().position(|&b| b == b'\n')
            .ok_or(anyhow!("no newline"))?;
        let line = &input[..line_end - 1]; // exclude \r
        let rest = &input[line_end + 1..];

        let parts: Vec<&[u8]> = line.split(|&b| b == b' ').collect();
        if parts.is_empty() {
            return Err(anyhow!("empty command"));
        }

        let cmd = std::str::from_utf8(parts[0])?;
        let cmd_type = match cmd {
            "mg" => CommandType::Get,
            "ms" => CommandType::Set,
            "md" => CommandType::Delete,
            "mn" => CommandType::Noop,
            _ => return Err(anyhow!("unknown command: {}", cmd)),
        };

        if parts.len() < 2 {
            return Err(anyhow!("missing key"));
        }

        let key_start = parts[0].len() + 1;
        let key_end = key_start + parts[1].len();

        let value_size = if cmd_type == CommandType::Set && parts.len() > 2 {
            Some(std::str::from_utf8(parts[2])?.parse()?)
        } else {
            None
        };

        Ok((ParsedCommand {
            cmd_type,
            key_range: key_start..key_end,
            value_size,
            flags: Flags::empty(),
        }, rest))
    }

    pub fn parse_response(&self, input: &[u8]) -> Result<ParsedResponse> {
        let line_end = input.iter().position(|&b| b == b'\n')
            .ok_or(anyhow!("no newline"))?;
        let line = &input[..line_end - 1];

        let parts: Vec<&[u8]> = line.split(|&b| b == b' ').collect();
        if parts.is_empty() {
            return Err(anyhow!("empty response"));
        }

        let resp_type = std::str::from_utf8(parts[0])?;
        let response = match resp_type {
            "VA" => {
                let size: u32 = std::str::from_utf8(parts[1])?.parse()?;
                Response::Found(size)
            }
            "EN" => Response::NotFound,
            "EX" => Response::Error,
            "HD" => Response::Found(0),
            _ => return Err(anyhow!("unknown response: {}", resp_type)),
        };

        Ok(ParsedResponse {
            resp: response,
            consumed: line_end + 1,
        })
    }
}
```

**Step 4: Update src/record/mod.rs**

```rust
pub mod capture;
pub mod stream_reassembler;
pub mod parser;

pub use capture::PacketCapture;
pub use parser::MemcacheParser;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test memcache_parser_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/record/parser.rs src/record/mod.rs tests/memcache_parser_tests.rs && git commit -m "feat: implement memcache protocol parser"
```

---

### Task 6: Implement Key Anonymization ✅ DONE

**Files:**
- Create: `src/record/anonymizer.rs`
- Modify: `src/record/mod.rs`
- Create: `tests/anonymizer_tests.rs`

**Step 1: Write test for anonymization**

Create `tests/anonymizer_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::record::Anonymizer;

    #[test]
    fn test_hash_deterministic() {
        let anon = Anonymizer::new(12345);

        let hash1 = anon.hash_key(b"testkey");
        let hash2 = anon.hash_key(b"testkey");

        assert_eq!(hash1, hash2, "hashing same key should produce same hash");
    }

    #[test]
    fn test_different_keys_different_hashes() {
        let anon = Anonymizer::new(12345);

        let hash1 = anon.hash_key(b"key1");
        let hash2 = anon.hash_key(b"key2");

        assert_ne!(hash1, hash2, "different keys should produce different hashes");
    }

    #[test]
    fn test_different_salts_different_hashes() {
        let anon1 = Anonymizer::new(12345);
        let anon2 = Anonymizer::new(54321);

        let hash1 = anon1.hash_key(b"testkey");
        let hash2 = anon2.hash_key(b"testkey");

        assert_ne!(hash1, hash2, "different salts should produce different hashes");
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test anonymizer_tests
```

Expected: FAIL - `Anonymizer` not defined.

**Step 3: Implement anonymizer in src/record/anonymizer.rs**

```rust
use siphasher::sip::SipHasher13;
use std::hash::{Hash, Hasher};

pub struct Anonymizer {
    salt: u64,
}

impl Anonymizer {
    pub fn new(salt: u64) -> Self {
        Anonymizer { salt }
    }

    pub fn hash_key(&self, key: &[u8]) -> u64 {
        let mut hasher = SipHasher13::new_with_key([self.salt, self.salt].as_slice());
        key.hash(&mut hasher);
        hasher.finish()
    }
}
```

**Step 4: Update src/record/mod.rs**

```rust
pub mod anonymizer;
pub use anonymizer::Anonymizer;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test anonymizer_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/record/anonymizer.rs src/record/mod.rs tests/anonymizer_tests.rs && git commit -m "feat: implement key anonymization with deterministic hashing"
```

---

## Record Phase: Integration

### Task 7: Implement Record Mode Record Writer ✅ DONE

**Files:**
- Create: `src/record/writer.rs`
- Modify: `src/record/mod.rs`
- Create: `tests/record_writer_tests.rs`

**Step 1: Write test for profile file writing**

Create `tests/record_writer_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::record::ProfileWriter;
    use membench::profile::{Event, Response, CommandType, Flags};
    use tempfile::NamedTempFile;

    #[test]
    fn test_write_profile() {
        let temp = NamedTempFile::new().unwrap();
        let path = temp.path().to_str().unwrap();

        let mut writer = ProfileWriter::new(path).unwrap();

        let event = Event {
            timestamp: 1000,
            conn_id: 1,
            cmd_type: CommandType::Get,
            key_hash: 0x123456789,
            key_size: 10,
            value_size: None,
            flags: Flags::empty(),
            response: Response::Found(100),
        };

        writer.write_event(&event).unwrap();
        writer.finish().unwrap();

        // Verify file was written and has content
        let metadata = std::fs::metadata(path).unwrap();
        assert!(metadata.len() > 0);
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test record_writer_tests
```

Expected: FAIL - `ProfileWriter` not defined.

**Step 3: Implement writer in src/record/writer.rs**

```rust
use anyhow::Result;
use std::fs::File;
use std::io::{BufWriter, Write};
use membench::profile::{Event, ProfileMetadata};
use std::collections::HashMap;

pub struct ProfileWriter {
    file: BufWriter<File>,
    metadata: ProfileMetadata,
    events_written: u64,
    first_timestamp: Option<u64>,
    last_timestamp: Option<u64>,
    connections: std::collections::HashSet<u32>,
}

impl ProfileWriter {
    pub fn new(path: &str) -> Result<Self> {
        let file = File::create(path)?;
        let mut writer = BufWriter::new(file);

        let metadata = ProfileMetadata::new();

        // Write metadata with length prefix
        let encoded_metadata = bincode::serialize(&metadata)?;
        writer.write_all(&(encoded_metadata.len() as u16).to_le_bytes())?;
        writer.write_all(&encoded_metadata)?;

        Ok(ProfileWriter {
            file: writer,
            metadata,
            events_written: 0,
            first_timestamp: None,
            last_timestamp: None,
            connections: std::collections::HashSet::new(),
        })
    }

    pub fn write_event(&mut self, event: &Event) -> Result<()> {
        let encoded = bincode::serialize(event)?;

        // Write event with u16 length prefix
        self.file.write_all(&(encoded.len() as u16).to_le_bytes())?;
        self.file.write_all(&encoded)?;

        self.events_written += 1;
        self.connections.insert(event.conn_id);

        if self.first_timestamp.is_none() {
            self.first_timestamp = Some(event.timestamp);
        }
        self.last_timestamp = Some(event.timestamp);

        *self.metadata.command_distribution
            .entry(event.cmd_type)
            .or_insert(0) += 1;

        Ok(())
    }

    pub fn finish(mut self) -> Result<()> {
        self.metadata.total_events = self.events_written;
        self.metadata.unique_connections = self.connections.len() as u32;

        if let (Some(first), Some(last)) = (self.first_timestamp, self.last_timestamp) {
            self.metadata.time_range = (first, last);
        }

        self.file.flush()?;
        Ok(())
    }
}
```

**Step 4: Update src/record/mod.rs**

```rust
pub mod writer;
pub use writer::ProfileWriter;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test record_writer_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/record/writer.rs src/record/mod.rs tests/record_writer_tests.rs && git commit -m "feat: implement profile file writer"
```

---

## Replay Phase: Profile Reading

### Task 8: Implement Profile Reader ✅ DONE

**Files:**
- Create: `src/replay/reader.rs`
- Modify: `src/replay/mod.rs`
- Create: `tests/replay_reader_tests.rs`

**Step 1: Write test for profile reading**

Create `tests/replay_reader_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::replay::ProfileReader;
    use membench::record::ProfileWriter;
    use membench::profile::{Event, Response, CommandType, Flags};
    use tempfile::NamedTempFile;

    #[test]
    fn test_read_profile() {
        let temp = NamedTempFile::new().unwrap();
        let path = temp.path().to_str().unwrap();

        // Write a profile
        let mut writer = ProfileWriter::new(path).unwrap();
        let event = Event {
            timestamp: 1000,
            conn_id: 1,
            cmd_type: CommandType::Get,
            key_hash: 0x123456789,
            key_size: 10,
            value_size: None,
            flags: Flags::empty(),
            response: Response::Found(100),
        };
        writer.write_event(&event).unwrap();
        writer.finish().unwrap();

        // Read it back
        let mut reader = ProfileReader::new(path).unwrap();
        let metadata = reader.metadata().clone();

        assert_eq!(metadata.total_events, 1);
        assert_eq!(metadata.unique_connections, 1);
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test replay_reader_tests
```

Expected: FAIL - `ProfileReader` not defined.

**Step 3: Implement reader in src/replay/reader.rs**

```rust
use anyhow::{Result, Context};
use std::fs::File;
use std::io::{BufReader, Read};
use membench::profile::{Event, ProfileMetadata};

pub struct ProfileReader {
    metadata: ProfileMetadata,
    events: Vec<Event>,
}

impl ProfileReader {
    pub fn new(path: &str) -> Result<Self> {
        let file = File::open(path)?;
        let mut reader = BufReader::new(file);

        // Read metadata with length prefix
        let mut len_bytes = [0u8; 2];
        reader.read_exact(&mut len_bytes)
            .context("failed to read metadata length")?;
        let metadata_len = u16::from_le_bytes(len_bytes) as usize;

        let mut metadata_bytes = vec![0u8; metadata_len];
        reader.read_exact(&mut metadata_bytes)
            .context("failed to read metadata")?;

        let metadata: ProfileMetadata = bincode::deserialize(&metadata_bytes)?;

        // Read events with length prefixes
        let mut events = Vec::new();
        loop {
            let mut len_bytes = [0u8; 2];
            match reader.read_exact(&mut len_bytes) {
                Ok(_) => {
                    let event_len = u16::from_le_bytes(len_bytes) as usize;
                    let mut event_bytes = vec![0u8; event_len];
                    reader.read_exact(&mut event_bytes)
                        .context("failed to read event data")?;

                    let event: Event = bincode::deserialize(&event_bytes)?;
                    events.push(event);
                }
                Err(e) if e.kind() == std::io::ErrorKind::UnexpectedEof => {
                    // End of file reached
                    break;
                }
                Err(e) => return Err(e.into()),
            }
        }

        Ok(ProfileReader { metadata, events })
    }

    pub fn metadata(&self) -> &ProfileMetadata {
        &self.metadata
    }

    pub fn events(&self) -> &[Event] {
        &self.events
    }
}
```

**Step 4: Update src/replay/mod.rs**

```rust
pub mod reader;
pub use reader::ProfileReader;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test replay_reader_tests
```

Expected: PASS or needs debugging—iterate until passing.

**Step 6: Commit**

```bash
git add src/replay/reader.rs src/replay/mod.rs tests/replay_reader_tests.rs && git commit -m "feat: implement profile file reader"
```

---

### Task 9: Implement Distribution Analysis

**Files:**
- Create: `src/replay/analyzer.rs`
- Modify: `src/replay/mod.rs`
- Create: `tests/replay_analyzer_tests.rs`

**Step 1: Write test for distribution analysis**

Create `tests/replay_analyzer_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::replay::DistributionAnalyzer;
    use membench::profile::{Event, Response, CommandType, Flags};

    #[test]
    fn test_analyze_command_distribution() {
        let events = vec![
            Event {
                timestamp: 1000,
                conn_id: 1,
                cmd_type: CommandType::Get,
                key_hash: 0x1,
                key_size: 10,
                value_size: None,
                flags: Flags::empty(),
                response: Response::Found(100),
            },
            Event {
                timestamp: 2000,
                conn_id: 1,
                cmd_type: CommandType::Set,
                key_hash: 0x2,
                key_size: 20,
                value_size: Some(50),
                flags: Flags::empty(),
                response: Response::Found(0),
            },
        ];

        let analysis = DistributionAnalyzer::analyze(&events);

        assert_eq!(analysis.total_events, 2);
        assert_eq!(analysis.command_distribution.get(&CommandType::Get), Some(&1));
        assert_eq!(analysis.command_distribution.get(&CommandType::Set), Some(&1));
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test replay_analyzer_tests
```

Expected: FAIL - `DistributionAnalyzer` not defined.

**Step 3: Implement analyzer in src/replay/analyzer.rs**

```rust
use std::collections::HashMap;
use membench::profile::{Event, CommandType, Response};

pub struct Distribution<T> {
    pub samples: Vec<(T, u64)>,
}

pub struct AnalysisResult {
    pub total_events: u64,
    pub command_distribution: HashMap<CommandType, u64>,
    pub key_size_distribution: Vec<(u32, u64)>,
    pub value_size_distribution: Vec<(u32, u64)>,
    pub response_distribution: HashMap<String, u64>,
    pub hit_rate: f64,
}

pub struct DistributionAnalyzer;

impl DistributionAnalyzer {
    pub fn analyze(events: &[Event]) -> AnalysisResult {
        let mut cmd_dist = HashMap::new();
        let mut key_size_dist = HashMap::new();
        let mut value_size_dist = HashMap::new();
        let mut response_dist = HashMap::new();
        let mut hit_count = 0;
        let mut total_responses = 0;

        for event in events {
            *cmd_dist.entry(event.cmd_type).or_insert(0) += 1;
            *key_size_dist.entry(event.key_size).or_insert(0) += 1;

            if let Some(size) = event.value_size {
                *value_size_dist.entry(size).or_insert(0) += 1;
            }

            let resp_type = match event.response {
                Response::Found(_) => "found",
                Response::NotFound => "notfound",
                Response::Error => "error",
            };
            *response_dist.entry(resp_type.to_string()).or_insert(0) += 1;

            if matches!(event.response, Response::Found(_)) {
                hit_count += 1;
            }
            total_responses += 1;
        }

        let hit_rate = if total_responses > 0 {
            hit_count as f64 / total_responses as f64
        } else {
            0.0
        };

        AnalysisResult {
            total_events: events.len() as u64,
            command_distribution: cmd_dist,
            key_size_distribution: key_size_dist
                .into_iter()
                .collect::<Vec<_>>(),
            value_size_distribution: value_size_dist
                .into_iter()
                .collect::<Vec<_>>(),
            response_distribution: response_dist,
            hit_rate,
        }
    }
}
```

**Step 4: Update src/replay/mod.rs**

```rust
pub mod analyzer;
pub mod reader;

pub use analyzer::{DistributionAnalyzer, AnalysisResult};
pub use reader::ProfileReader;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test replay_analyzer_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/replay/analyzer.rs src/replay/mod.rs tests/replay_analyzer_tests.rs && git commit -m "feat: implement distribution analysis for replay"
```

---

### Task 10: Implement Traffic Generator

**Files:**
- Create: `src/replay/generator.rs`
- Modify: `src/replay/mod.rs`
- Create: `tests/replay_generator_tests.rs`

**Step 1: Write test for traffic generation**

Create `tests/replay_generator_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::replay::{TrafficGenerator, AnalysisResult};
    use membench::profile::{CommandType, Response};
    use std::collections::HashMap;

    #[test]
    fn test_generator_produces_commands() {
        let mut cmd_dist = HashMap::new();
        cmd_dist.insert(CommandType::Get, 80);
        cmd_dist.insert(CommandType::Set, 20);

        let analysis = AnalysisResult {
            total_events: 100,
            command_distribution: cmd_dist,
            key_size_distribution: vec![(10, 50), (20, 50)],
            value_size_distribution: vec![(100, 50), (200, 50)],
            response_distribution: HashMap::new(),
            hit_rate: 0.8,
        };

        let gen = TrafficGenerator::new(analysis);
        let cmd = gen.next_command();

        assert!(matches!(
            cmd.cmd_type,
            CommandType::Get | CommandType::Set
        ));
    }
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test --test replay_generator_tests
```

Expected: FAIL - `TrafficGenerator` not defined.

**Step 3: Implement generator in src/replay/generator.rs**

```rust
use membench::profile::{CommandType, Event, Flags, Response};
use rand::Rng;
use std::collections::HashMap;
use super::analyzer::AnalysisResult;

pub struct TrafficGenerator {
    analysis: AnalysisResult,
    rng: rand::rngs::ThreadRng,
}

impl TrafficGenerator {
    pub fn new(analysis: AnalysisResult) -> Self {
        TrafficGenerator {
            analysis,
            rng: rand::thread_rng(),
        }
    }

    pub fn next_command(&mut self) -> Event {
        let cmd_type = self.sample_command();
        let key_size = self.sample_key_size();
        let value_size = if cmd_type == CommandType::Set {
            Some(self.sample_value_size())
        } else {
            None
        };

        // Determine response based on hit rate
        let response = if self.rng.gen::<f64>() < self.analysis.hit_rate {
            Response::Found(value_size.unwrap_or(0))
        } else {
            Response::NotFound
        };

        Event {
            timestamp: self.rng.gen::<u64>(),
            conn_id: self.rng.gen::<u32>() % 4, // Limit to 4 connections
            cmd_type,
            key_hash: self.rng.gen::<u64>(),
            key_size,
            value_size,
            flags: Flags::empty(),
            response,
        }
    }

    fn sample_command(&mut self) -> CommandType {
        let total: u64 = self.analysis.command_distribution.values().sum();
        let mut r = self.rng.gen::<u64>() % total;

        for (cmd, count) in &self.analysis.command_distribution {
            if r < *count {
                return *cmd;
            }
            r -= count;
        }

        CommandType::Get
    }

    fn sample_key_size(&mut self) -> u32 {
        let total: u64 = self.analysis.key_size_distribution.iter().map(|(_, c)| c).sum();
        let mut r = self.rng.gen::<u64>() % total;

        for (size, count) in &self.analysis.key_size_distribution {
            if r < *count {
                return *size;
            }
            r -= count;
        }

        10
    }

    fn sample_value_size(&mut self) -> u32 {
        if self.analysis.value_size_distribution.is_empty() {
            return 100;
        }

        let total: u64 = self.analysis.value_size_distribution.iter().map(|(_, c)| c).sum();
        let mut r = self.rng.gen::<u64>() % total;

        for (size, count) in &self.analysis.value_size_distribution {
            if r < *count {
                return *size;
            }
            r -= count;
        }

        100
    }
}
```

**Step 4: Update src/replay/mod.rs**

```rust
pub mod analyzer;
pub mod generator;
pub mod reader;

pub use analyzer::{DistributionAnalyzer, AnalysisResult};
pub use generator::TrafficGenerator;
pub use reader::ProfileReader;
```

**Step 5: Run test to verify it passes**

```bash
cargo test --test replay_generator_tests
```

Expected: PASS.

**Step 6: Commit**

```bash
git add src/replay/generator.rs src/replay/mod.rs tests/replay_generator_tests.rs && git commit -m "feat: implement semi-deterministic traffic generator"
```

---

### Task 11: Implement Replay Client

**Files:**
- Create: `src/replay/client.rs`
- Modify: `src/replay/mod.rs`
- Create: `tests/replay_client_tests.rs` (integration test, may skip if no test memcached)

**Step 1: Write test for replay client**

Create `tests/replay_client_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::replay::ReplayClient;

    #[test]
    fn test_client_connection() {
        // This is an integration test that requires a running memcached server
        // For now, just test the interface exists
        let result = ReplayClient::new("127.0.0.1:11211", 100);
        // Either succeeds or fails gracefully
        assert!(result.is_ok() || result.is_err());
    }
}
```

**Step 2: Run test to verify it fails or passes**

```bash
cargo test --test replay_client_tests
```

**Step 3: Implement client in src/replay/client.rs**

```rust
use anyhow::Result;
use std::net::TcpStream;
use std::io::{Read, Write};
use membench::profile::{Event, CommandType};

pub struct ReplayClient {
    stream: TcpStream,
    buffer: Vec<u8>,
}

impl ReplayClient {
    pub fn new(target: &str, buf_capacity: usize) -> Result<Self> {
        let stream = TcpStream::connect(target)?;
        Ok(ReplayClient {
            stream,
            buffer: vec![0u8; buf_capacity],
        })
    }

    pub fn send_command(&mut self, event: &Event) -> Result<()> {
        let cmd = self.build_command_string(event);
        self.stream.write_all(cmd.as_bytes())?;
        Ok(())
    }

    pub fn read_response(&mut self) -> Result<Vec<u8>> {
        let n = self.stream.read(&mut self.buffer)?;
        Ok(self.buffer[..n].to_vec())
    }

    fn build_command_string(&self, event: &Event) -> String {
        match event.cmd_type {
            CommandType::Get => {
                format!("mg {} v\r\n", "key")  // Placeholder key
            }
            CommandType::Set => {
                let size = event.value_size.unwrap_or(0);
                format!("ms {} {}\r\n{}\r\n", "key", size, "value")
            }
            CommandType::Delete => {
                format!("md {}\r\n", "key")
            }
            CommandType::Noop => {
                "mn\r\n".to_string()
            }
        }
    }
}
```

**Step 4: Update src/replay/mod.rs**

```rust
pub mod analyzer;
pub mod client;
pub mod generator;
pub mod reader;

pub use analyzer::{DistributionAnalyzer, AnalysisResult};
pub use client::ReplayClient;
pub use generator::TrafficGenerator;
pub use reader::ProfileReader;
```

**Step 5: Run test**

```bash
cargo test --test replay_client_tests
```

Expected: PASS or skip if no server available.

**Step 6: Commit**

```bash
git add src/replay/client.rs src/replay/mod.rs tests/replay_client_tests.rs && git commit -m "feat: implement replay client for sending memcache commands"
```

---

## CLI Integration

### Task 12: Implement Record Subcommand

**Files:**
- Modify: `src/main.rs`
- Modify: `src/lib.rs` (if needed)

**Step 1: Add record command implementation**

Update `src/main.rs`:
```rust
use membench::{record, replay};
use clap::{Parser, Subcommand};
use std::time::SystemTime;
use std::path::Path;

#[derive(Parser)]
#[command(name = "membench")]
#[command(about = "Privacy-preserving memcache traffic capture and replay")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Capture memcache traffic from network interface
    Record {
        #[arg(short, long)]
        interface: String,
        #[arg(short, long, default_value = "11211")]
        port: u16,
        #[arg(short, long)]
        output: String,
        #[arg(short, long)]
        salt: Option<u64>,
    },
    /// Replay traffic from profile against target server
    Replay {
        #[arg(short, long)]
        input: String,
        #[arg(short, long, default_value = "localhost:11211")]
        target: String,
        #[arg(short, long, default_value = "4")]
        concurrency: usize,
    },
}

#[tokio::main]
async fn main() {
    tracing_subscriber::fmt::init();
    let cli = Cli::parse();

    match cli.command {
        Commands::Record { interface, port, output, salt } => {
            let salt = salt.unwrap_or_else(|| {
                SystemTime::now()
                    .duration_since(SystemTime::UNIX_EPOCH)
                    .unwrap()
                    .as_secs()
            });

            println!("Recording from {}:{} to {} (salt: {})", interface, port, output, salt);
            // Implementation will follow
        }
        Commands::Replay { input, target, duration, concurrency } => {
            println!("Replaying from {} to {} for {} seconds with {} concurrent connections",
                     input, target, duration, concurrency);
            // Implementation will follow
        }
    }
}
```

**Step 2: Run to verify compilation**

```bash
cargo build
```

Expected: Compiles successfully.

**Step 3: Commit**

```bash
git add src/main.rs && git commit -m "feat: add basic record and replay CLI stubs"
```

---

### Task 13: Implement Replay Subcommand Execution

**Files:**
- Modify: `src/main.rs`

**Step 1: Implement replay execution**

Update `src/main.rs` to add replay logic:
```rust
Commands::Replay { input, target, concurrency } => {
    if let Err(e) = run_replay(&input, &target, concurrency).await {
        eprintln!("Replay error: {}", e);
        std::process::exit(1);
    }
}
```

Add replay function after main:
```rust
async fn run_replay(
    input: &str,
    target: &str,
    concurrency: usize,
) -> anyhow::Result<()> {
    use membench::replay::{ProfileReader, DistributionAnalyzer, TrafficGenerator};

    let reader = ProfileReader::new(input)?;
    let analysis = DistributionAnalyzer::analyze(reader.events());

    println!("Profile loaded: {} events, hit rate: {:.2}%",
             analysis.total_events, analysis.hit_rate * 100.0);

    let mut stats = ReplayStats::new();

    loop {
        for _ in 0..concurrency {
            let mut gen = TrafficGenerator::new(analysis.clone());
            let event = gen.next_command();

            match membench::replay::ReplayClient::new(target, 65536) {
                Ok(mut client) => {
                    match client.send_command(&event) {
                        Ok(_) => stats.sent += 1,
                        Err(e) => {
                            stats.errors += 1;
                            tracing::warn!("Send error: {}", e);
                        }
                    }
                }
                Err(e) => {
                    stats.errors += 1;
                    tracing::warn!("Connection error: {}", e);
                }
            }
        }
    }
}

struct ReplayStats {
    sent: u64,
    errors: u64,
}

impl ReplayStats {
    fn new() -> Self {
        ReplayStats { sent: 0, errors: 0 }
    }
}
```

**Step 2: Update Cargo.toml to make membench a library**

Add to Cargo.toml:
```toml
[lib]
name = "membench"
path = "src/lib.rs"

[[bin]]
name = "membench"
path = "src/main.rs"
```

**Step 3: Run to verify**

```bash
cargo build
```

Expected: Compiles successfully.

**Step 4: Commit**

```bash
git add src/main.rs Cargo.toml && git commit -m "feat: implement replay subcommand execution"
```

---

## Final Testing & Documentation

### Task 14: End-to-End Integration Test

**Files:**
- Create: `tests/e2e_tests.rs`

**Step 1: Write end-to-end test**

Create `tests/e2e_tests.rs`:
```rust
#[cfg(test)]
mod tests {
    use membench::{
        profile::{Event, Response, CommandType, Flags},
        record::ProfileWriter,
        replay::{ProfileReader, DistributionAnalyzer},
    };
    use tempfile::NamedTempFile;

    #[test]
    fn test_capture_analyze_replay_workflow() {
        let temp = NamedTempFile::new().unwrap();
        let path = temp.path().to_str().unwrap();

        // Write sample profile
        let mut writer = ProfileWriter::new(path).unwrap();
        for i in 0..100 {
            let event = Event {
                timestamp: 1000 + i,
                conn_id: i % 4,
                cmd_type: if i % 5 == 0 {
                    CommandType::Set
                } else {
                    CommandType::Get
                },
                key_hash: (i as u64).wrapping_mul(0x123456789),
                key_size: 10 + (i % 20) as u32,
                value_size: if i % 5 == 0 {
                    Some(100 + (i % 200) as u32)
                } else {
                    None
                },
                flags: Flags::empty(),
                response: if i % 10 == 0 {
                    Response::NotFound
                } else {
                    Response::Found((i * 10) as u32)
                },
            };
            writer.write_event(&event).unwrap();
        }
        writer.finish().unwrap();

        // Read profile
        let reader = ProfileReader::new(path).unwrap();
        assert_eq!(reader.metadata().total_events, 100);

        // Analyze
        let analysis = DistributionAnalyzer::analyze(reader.events());
        assert_eq!(analysis.total_events, 100);
        assert!(analysis.hit_rate > 0.0 && analysis.hit_rate < 1.0);

        println!("E2E Test: Profile created, read, and analyzed successfully");
    }
}
```

**Step 2: Run test**

```bash
cargo test --test e2e_tests
```

Expected: PASS.

**Step 3: Commit**

```bash
git add tests/e2e_tests.rs && git commit -m "test: add end-to-end integration test"
```

---

### Task 15: Final Build & Documentation

**Files:**
- Create: `README.md`
- Create: `docs/USAGE.md`

**Step 1: Create README.md**

```markdown
# membench - Privacy-Preserving Memcache Traffic Benchmarking

membench captures memcache traffic, anonymizes keys and values, and replays realistic workload patterns for benchmarking.

## Features

- **Privacy-Preserving Capture:** Captures memcache protocol traffic and stores only key/value size distributions and command patterns
- **Deterministic Key Hashing:** Hash keys with configurable salt for reproducible anonymization
- **Distribution-Based Replay:** Replays traffic matching captured command, key size, and value size distributions
- **Zero Production Impact:** Uses libpcap for passive network capture

## Quick Start

### Capture Traffic

```bash
sudo membench record --interface lo --port 11211 --output profile.bin
```

### Replay Traffic

```bash
membench replay --input profile.bin --target localhost:11211 --duration 60 --concurrency 4
```

## Installation

```bash
cargo install --path .
```

## Architecture

See `docs/ARCHITECTURE.md` for design details.
```

Create `docs/USAGE.md`:
```markdown
# membench Usage Guide

## Record Mode

Captures memcache traffic from a network interface and creates an anonymized profile.

### Command

```bash
membench record \
  --interface lo \
  --port 11211 \
  --output profile.bin \
  [--salt SEED]
```

### Options

- `--interface` (required): Network interface to capture (e.g., `lo`, `eth0`)
- `--port` (required): Memcache port to filter
- `--output` (required): Output profile file path
- `--salt` (optional): Hash seed for key anonymization (default: random)

### Example

```bash
sudo membench record --interface eth0 --port 11211 --output production.bin --salt 12345
```

## Replay Mode

Reads a profile and replays traffic against a target memcached server.

### Command

```bash
membench replay \
  --input profile.bin \
  --target localhost:11211 \
  [--duration SECONDS] \
  [--concurrency N]
```

### Options

- `--input` (required): Profile file path
- `--target` (optional): Target memcached address (default: localhost:11211)
- `--duration` (optional): Replay duration in seconds (default: 60)
- `--concurrency` (optional): Concurrent connections (default: 4)

### Example

```bash
membench replay --input production.bin --target server:11211 --duration 120 --concurrency 8
```

## Profile File Format

Profiles are binary files containing:
1. ProfileMetadata (magic, version, stats)
2. Serialized Event records

Each Event contains:
- Timestamp
- Connection ID
- Command type (Get, Set, Delete, Noop)
- Key hash (u64)
- Key size
- Value size (optional)
- Flags
- Response type (Found, NotFound, Error)
```

**Step 2: Create these files**

(Use Write tool)

**Step 3: Run final tests**

```bash
cargo test
cargo build --release
```

Expected: All tests pass, release build succeeds.

**Step 4: Commit**

```bash
git add README.md docs/USAGE.md && git commit -m "docs: add README and usage guide"
```

---

## Summary

This plan implements a complete privacy-preserving memcache traffic capture and replay tool with:

- **Record phase:** Captures traffic via libpcap, anonymizes keys, writes profiles
- **Replay phase:** Reads profiles, analyzes distributions, generates semi-deterministic traffic
- **15 bite-sized tasks** following TDD (test-first development)
- **Comprehensive testing:** Unit, integration, and end-to-end tests
- **Full CLI:** `membench record` and `membench replay` subcommands

Each task can be implemented in 2-5 minutes and includes failing tests, implementation, passing tests, and commits.
